{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r ./../requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd851986-ecc8-40c1-8c6f-8d2fe5cb9811",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Introduction\n",
    "As highlighted in the accompanying blog post, \"effective risk management requires real-time water risk data that is continuously fed into risk models\". This is true. What is *also* true, is that using real-time data without any quality checks on that data poses threats to the validity of model outputs. We've all heard some version of the adage, \"data quality in equals data quality out\".\n",
    "\n",
    "In most cases, there is a tradeoff between utilizing  data with the lowest possible latency and ensuring the data has been put through rigorous quality testing. Divirod addresses this issue by implementing data quality checks and standardization as data is ingested into the data lake in real time. Data quality scores are assigned for *every* data point in the Divirod data lake during the ingestion processes. This removes a huge burden for users of this data. \n",
    "\n",
    "For example, yes, modelers can query their own data from both USGS and NOAA to feed into water risk models. But is that data standardized? What about unit conversions? How do you know if the data set contains outliers from faulty gauges, etc.?  The USGS and NOAA readings for your region of interest from just this morning? In the data lake - already standardized, quality checked, outliers and discontinuities flagged, and accessible to you from a single end point! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d8ba7c9-edda-42aa-a881-9a2e023d9271",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# @hidden_cell\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "\n",
    "image_path = './../images/divirod_data_diagram.png'\n",
    "\n",
    "# Function to get Base64 string of an image\n",
    "def get_image_base64(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "image_base64 = get_image_base64(image_path)\n",
    "\n",
    "# Create an HTML string with the Base64 embedded and width set to 100%\n",
    "html = f'<img src=\"data:image/jpg;base64,{image_base64}\" style=\"width:100%;\">'\n",
    "\n",
    "# Display the image in the notebook\n",
    "display(HTML(html))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fddd53c-b46e-47b2-be11-155c42b83895",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Goal\n",
    "The purpose of this notebook is to provide transparency for customers as to how Divirod uses the Databricks platform in combination with Spark streaming to couple low latency with high standards for data quality checks. Divirod continuously ingests, standardizes, and quality checks 30 million water measurements daily across 20,000 + locations from providers around the globe using Spark Streaming; this notebook is mean to give a glimpse as to how we do that, and give customers confidence in our data processing pipeline. The goals of this accelerator notebook are three-fold:\n",
    "\n",
    "* Provide transparency for (part of) Divirod's data quality pipeline implemented as part of the ingestion pipeline\n",
    "* Highlight how implementing these checks during the ingestion process with spark streaming addresses the traditional tradeoff between ensuring high data quality and utilizing low latency data for model inputs.\n",
    "* Provide a technical example, for those interested, on how data scientists and developers can implement similar checks on ingestion pipelines constructed within the Databricks platform.\n",
    "\n",
    "This notebook will contain a combination of detailed code for execution of this process, as well as explanatory text intermingled throughout."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a33f92bf-891b-46a7-9217-c5d57d8481ef",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The below graphic serves as a reference to where the content within this notebook sits in relation to Divirod's overall data ingestion pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ecd985c-35ea-4143-a406-1c35890b1439",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "from IPython.display import HTML\n",
    "\n",
    "image_path = './../images/architecture_diagram_qual_checks.png'\n",
    "\n",
    "# Function to get Base64 string of an image\n",
    "def get_image_base64(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "image_base64 = get_image_base64(image_path)\n",
    "\n",
    "# Create an HTML string with the Base64 embedded and width set to 100%\n",
    "html = f'<img src=\"data:image/jpg;base64,{image_base64}\" style=\"width:100%;\">'\n",
    "\n",
    "# Display the image in the notebook\n",
    "display(HTML(html))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4175cb16-90fe-47ef-8b4f-f7d008c0012d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Example Workflow Explanation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6c200d2-13ce-4991-ad0b-2e493d36755f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Divirod assigns two data quality metrics for each record in the Divirod delta lake as they are ingested. One is to designate a data quality standard, classified as: 'gold', 'silver', or 'bronze'. The other is a diagnostic metric that can be used to identify what specific issues are impacting a record. The purpose of the diagnostic metric is to a) Give insight to operations as to potential sensor issues, and b) Allow users a quick understanding of what data quality issues apply to a specific record. \n",
    "\n",
    "**NOTE: Only \"Completeness\" and \"Out of Range\" checks are performed in this notebook!**\n",
    "Divirod also implements checks out discontinuities and physically-invalid data points (outliers).\n",
    "\n",
    "\n",
    "### Diagnostic\n",
    "To determine data quality we are checking for four main issues:\n",
    "* **Incomplete fields**\n",
    "  * Looks at the completeness level of these priority variables: instrument_id, time, height_native, datum_native, provider_id, last_update\n",
    "* **Values out of range**\n",
    "  * Checks for time stamps in the future, impossible combintations for lat/lons, accuracies greater than 1, unknown provider and instrument ids\n",
    "* **Discontinuous** (Proprietary, not part of this accelerator code.)\n",
    "  * Checks to make sure that the instrument has not missed any expected data collection intervals. \n",
    "* **Physically invalid** (Proprietary, not part of this accelerator code.)\n",
    "  * Checks to make sure the rate of change over each data interval period is physically plausible.\n",
    "\n",
    "The diagnostic metric will flag if one (or more) of these data errors is occurring. The diagnostic metric is broken out as follows (note: these are already broken out and interpretable in the summary table)\n",
    "\n",
    "\n",
    " * **0 = No issues**\n",
    " * 1 = Physically invalid\n",
    " * 2 = Discontinuous\n",
    " * **4 = Values out of range**\n",
    " * **8 = Incomplete fields**\n",
    " * 3 = Physically invalid + Discontinuous\n",
    " * 5 = Physically invalid + Values out of range\n",
    " * 9 = Physically invalid + Incomplete fields\n",
    " * 6 = Discontinuous + Values out of range\n",
    " * 10 = Discontinuous + Incomplete fields\n",
    " * **12 = Values out of range + Incomplete fields**\n",
    " * 7 = Physically invalid + Discontinuous + Values out of range\n",
    " * 11 = Physically invalid + Discontinuous + Incomplete fields\n",
    " * 13 = Physically invalid + Values out of range + Incomplete fields\n",
    " * 14 = Discontinuous + Values out of range + Incomplete fields\n",
    " * 15 = Physically invalid + Discontinuous + Values out of range + Incomplete fields\n",
    "\n",
    "\n",
    "### Qualitative\n",
    "We wanted a high level data quality metric that can be easily interpreted both internally and externally to understand the data quality of each record. We landed on ratings of 'gold', 'silver', and 'bronze'. **Important note:** **This is different than Databricks' medallion architecture. Divirod chose this metric because it can be interpreted in a similar manner, but this data quality designation is assigned by Divirod for only the records in Divirod's data lake.**\n",
    "\n",
    "Gold, silver, and bronze data qualities are defined as follows:\n",
    "\n",
    "| | Completeness  | Value Ranges  | Continuity  | Physical Correctness  |\n",
    "|----------|--------------|-----------|------------|-------------|\n",
    "|Gold| All values present| All values within valid range|All values are continuous|For this type of site, data makes sense|\n",
    "|Silver| \"last_update\" can be missing     | May have incorrect lat, lon, or accuracy | A few missing data points, but still able to interpret trends based on site type|Generally, data is plausible|\n",
    "|Bronze| Anything less than silver| Anything less than silver| Anything less than silver|Anything less than silver|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b6c71ea-b50e-4ddd-936a-da9299c2dac4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Code Example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b77d4a3c-4993-4777-8a8a-80367a7afff1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd6f6244-4284-443b-8510-10a0c7ef80db",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2a9dda0-bf52-4380-bf48-0e1a7f622b25",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    StringType,\n",
    "    LongType,\n",
    "    DoubleType,\n",
    "    TimestampType,\n",
    "    IntegerType,\n",
    ")\n",
    "\n",
    "import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "\n",
    "# for typing\n",
    "from pyspark.sql import dataframe as sparkDataFrame"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53c65584-5381-4327-9ea0-b724bdf66e9f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Stream Configuration\n",
    "This section simulates the data stream coming out of Divirod's ETL pipeline. The defined schema is a mirror of the schema in Divirod's water_level table in the productionized delta lake. \n",
    "These same columns are present for all instruments in the data lake (both Divirod instruments, as well as third party). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aba30e2e-084d-4396-88ce-6067ab94cc41",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# this file path will be updated to the appropriate path in the github repo\n",
    "billings_2022_data_path = \"./../data/billings_11074_all_measurements_2022\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87ac7a27-eb73-4054-a732-aefeaf7ca97f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "billings_data_schema = StructType(\n",
    "    [\n",
    "        StructField(\"instrument_id\", IntegerType(), True),\n",
    "        StructField(\"epoch\", LongType(), True),\n",
    "        StructField(\"time\", TimestampType(), True),\n",
    "        StructField(\"year\", IntegerType(), True),\n",
    "        StructField(\"height_native\", DoubleType(), True),\n",
    "        StructField(\"precision\", DoubleType(), True),\n",
    "        StructField(\"datum_native\", StringType(), True),\n",
    "        StructField(\"accuracy_native\", DoubleType(), True),\n",
    "        StructField(\"height_unified\", DoubleType(), True),\n",
    "        StructField(\"datum_unified\", StringType(), True),\n",
    "        StructField(\"accuracy_unified\", DoubleType(), True),\n",
    "        StructField(\"provider_id\", IntegerType(), True),\n",
    "        StructField(\"data_level\", StringType(), True),\n",
    "        StructField(\"confidence\", DoubleType(), True),\n",
    "        StructField(\"last_update\", TimestampType(), True),\n",
    "        StructField(\"last_update_epoch\", LongType(), True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DivirodSolutionAccelerator1\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7659d5ff-098d-452d-b76f-f49bbb9e91a6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read Parquet file as streaming DataFrame\n",
    "simulated_etl_stream = (\n",
    "    spark.readStream.format(\"parquet\")\n",
    "    .schema(billings_data_schema)\n",
    "    .load(billings_2022_data_path)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "033e01ac-0540-4f98-94b1-230dd411aa8f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "542955cc-56e1-4d3c-b58b-b59d7c47222e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# example list of allowable provider ids (corresponding to USGS, UBSR, NOAA, etc.)\n",
    "allowable_provider_ids = [98, 121, 0, 109]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fb8b86f-4da2-4e40-8d25-b24579c345b0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Data Quality Functions\n",
    "The below functions illustrate how data quality checks may be implemented in a real time stream. For confidentiality reasons, the entire data quality workflow actually implemented by Divirod during the ingestion process is not included in this notebook. Only very simple data quality checks such as checking for completeness and valid ranges are included in this demo notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2aac2af8-dc1a-4bfa-b965-489fc4bf9bcc",
     "showTitle": true,
     "title": "Data Quality Functions - Spark"
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# COMPLETENESS FUNCTIONS\n",
    "# =============================================================================\n",
    "# Completeness functions check that all columns/variables that we would want to be filled out for \"gold\" or \"silver\"\n",
    "# data quality levels are complete.\n",
    "\n",
    "\n",
    "def check_completeness_qual(\n",
    "    df: sparkDataFrame, columns_to_check: list, qual_level=None\n",
    ") -> sparkDataFrame:\n",
    "    \"\"\"This function will check for the 'completeness' of each variable defined in the columns list\n",
    "    for each reacord in the dataframe. Dependent on the data type stored in each column in the columns list,\n",
    "    this function will check for the following incomplete values:\n",
    "\n",
    "    None type, null, np.nan, '' (empty string), and 'None'\n",
    "\n",
    "    A new column, 'incomplete' (bool), is added to the datframe. For each row, if an incomplete\n",
    "    value is found in one of the input columns this value will be 1, otherwise will be 0\n",
    "    if all of the input columns contain acceptable data points.\n",
    "\n",
    "    If the function is being applied with the purpose of assigning the final data quality metric for the record,\n",
    "    inputs should be added\n",
    "    to identify if the function is to be applied for the 'gold' or 'silver' standard.\n",
    "\n",
    "    Args:\n",
    "        df (sparkDataFrame): spark dataframe created from an sql query over which the completeness check will be run\n",
    "        columns_to_check (list): list of input columns over which the completeness check will be performed\n",
    "        qual_level (str, optional): Default is None. In this scenario, a completeness  check will be performed for the input columns with the results in a column titled, 'incomplete'. Otherwise, 'gold' or 'silver' should be\n",
    "        used as inputs here for the final quality metric assignment.\n",
    "\n",
    "    Returns:\n",
    "        sparkDataFrame: input dataframe with added bool column flagging if each record\n",
    "    has incomplete or complete values for each of the columns defined in the input list.\n",
    "    \"\"\"\n",
    "    completeness_expressions = []\n",
    "    for column in columns_to_check:\n",
    "        if df.schema[column].dataType in [\"double\", \"float\"]:\n",
    "            completeness_expressions.append(\n",
    "                (F.col(column).isNull())\n",
    "                | (F.isnan(F.col(column)))\n",
    "                | (F.col(column) == \"\")\n",
    "                | (F.col(column).isNull() & (F.col(column).cast(\"string\") == \"None\"))\n",
    "                |\n",
    "                # unknown values for USGS are input as -999999.00\n",
    "                (F.col(column) == -999999.00)\n",
    "            )\n",
    "        elif df.schema[column].dataType in [\"timestamp\"]:\n",
    "            completeness_expressions.append(\n",
    "                F.col(column).isNull() | (F.col(column) == \"\")\n",
    "            )\n",
    "        else:\n",
    "            completeness_expressions.append(\n",
    "                (F.col(column).isNull())\n",
    "                | (F.col(column) == \"\")\n",
    "                | (F.col(column).isNull() & (F.col(column).cast(\"string\") == \"None\"))\n",
    "            )\n",
    "\n",
    "    # Use the coalesce function to check if any of the completeness_expressions are true\n",
    "    # set initial state\n",
    "    completeness_condition = completeness_expressions[0]\n",
    "\n",
    "    for completeness_expression in completeness_expressions[1:]:\n",
    "        completeness_condition = completeness_condition | completeness_expression\n",
    "\n",
    "    # evaluate the completeness_condtion across all rows of the DataFrame and assign boolean value in a new 'incomplete' column\n",
    "    if qual_level:\n",
    "        df = df.withColumn(\n",
    "            f\"incomplete_{qual_level}\", F.coalesce(completeness_condition, F.lit(False))\n",
    "        )\n",
    "    else:\n",
    "        df = df.withColumn(\n",
    "            \"incomplete\", F.coalesce(completeness_condition, F.lit(False))\n",
    "        )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# VALUE CHECK FUNCTIONS\n",
    "# =============================================================================\n",
    "# Value check functions perform checks to make sure that value ranges for lat/lon, timestamps, etc are all within\n",
    "# reason.\n",
    "\n",
    "\n",
    "def check_value_ranges(\n",
    "    df: sparkDataFrame, max_allowable_epoch: int, provider_ids: list, qual_level=None\n",
    ") -> sparkDataFrame:\n",
    "    \"\"\"This function checks whether the values in the input columns, columns_to_check, are appropriate, as dictated\n",
    "    by the input, allowable ranges.\n",
    "\n",
    "    A new column, 'out_of_range' (bool), is added to the datframe.\n",
    "\n",
    "    If the function is being applied with the purpose of assigning the final data quality metric for the record,\n",
    "    inputs should be added to identify if the function is to be applied for the 'gold' or 'silver' standard.\n",
    "\n",
    "    Args:\n",
    "        df (sparkDataFrame): spark dataframe created from an sql query over which the value ranges check is run.\n",
    "        max_allowable_epoch (int): max reasonable epoch\n",
    "        provider_ids (list): list of acceptable, known provider_ids\n",
    "        qual_level (str, optional): Default is None. In this scenario, a completeness check will be performed for\n",
    "        the input columns with the results in a column titled, 'incomplete'. Otherwise, 'gold' or 'silver' should be\n",
    "        used as inputs here for the final quality metric assignment.\n",
    "\n",
    "    Returns:\n",
    "        sparkDataFrame: input dataframe with added bool column flagging if each record\n",
    "        has valid values for each of the columns defined in the input list.\n",
    "    \"\"\"\n",
    "    range_expressions = []\n",
    "\n",
    "    range_expressions.append(F.col(\"epoch\") > max_allowable_epoch)\n",
    "\n",
    "    if qual_level == \"gold\":\n",
    "        # only check this for gold for now\n",
    "        # check acceptable accuracy native ranges\n",
    "        range_expressions.append(F.col(\"accuracy_native\") < 0)\n",
    "        range_expressions.append(F.col(\"accuracy_native\") > 1)\n",
    "\n",
    "    id_query = [F.col(\"provider_id\") == str(_id) for _id in provider_ids]\n",
    "    range_expressions = id_query\n",
    "\n",
    "    # Use the coalesce to check if any of the range_expressions are true\n",
    "    # set initial state\n",
    "    range_condition = range_expressions[0]\n",
    "\n",
    "    for range_expression in range_expressions[1:]:\n",
    "        range_condition = range_condition | range_expression\n",
    "\n",
    "    # evaluate the range_condtion across all rows of the DataFrame and assign the inverse boolean value in a new 'out_of_range' column\n",
    "    df = df.withColumn(\"id_in_range\", range_condition)\n",
    "\n",
    "    if qual_level:\n",
    "        # df_with_range_col = df.withColumn(f'out_of_range_{qual_level}', range_condition)\n",
    "        df_with_range_col = df.withColumn(\n",
    "            f\"out_of_range_{qual_level}\", ~F.col(\"id_in_range\")\n",
    "        )\n",
    "\n",
    "    # only running range check for a specific use case\n",
    "    else:\n",
    "        # df_with_range_col = df.withColumn('out_of_range', range_condition)\n",
    "        df_with_range_col = df.withColumn(\"out_of_range\", ~F.col(\"id_in_range\"))\n",
    "\n",
    "    df_with_range_col = df_with_range_col.drop(F.col(\"id_in_range\"))\n",
    "\n",
    "    return df_with_range_col\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# DATA QUALITY IMPLEMENTATION FUNCTIONS\n",
    "# =============================================================================\n",
    "# This sections outlines the consolidation of the above functions for the actual application of the checks.\n",
    "\n",
    "\n",
    "def perform_quality_checks(\n",
    "    df: sparkDataFrame,\n",
    "    max_allowable_epoch: int,\n",
    "    gold_completeness_cols: list,\n",
    "    silver_completeness_cols: list,\n",
    "    gold_quality_cols: list,\n",
    "    silver_quality_cols: list,\n",
    ") -> sparkDataFrame:\n",
    "    \"\"\"Performs a sequence of functions to determine the final data quality designation of 'gold', 'silver', or\n",
    "    'bronze' for each record in the delta lake water_level table.\n",
    "\n",
    "    Args:\n",
    "        df (sparkDataFrame):  dataframe over which the data quality of each record will be assigned and a final data\n",
    "        quality designation assigned\n",
    "        max_allowable_epoch (int): max reasonable epoch\n",
    "        gold_completeness_cols (list): list of completeness columns which need to be complete in order to receive a \"gold\" rating\n",
    "        silver_quality_cols (list): list of completeness columns across which to run checks for \"silver\" rating\n",
    "        gold_quality_cols (list): list of quality columns across which to run checks for \"gold\" rating\n",
    "        silver_quality_cols (list): list of quality columns across which to run checks for \"silver\" rating\n",
    "    Returns:\n",
    "        sparkDataFrame: input spark dataframe with the final data quality designation of 'gold', 'silver', or 'bronze'\n",
    "        assigned for each row\n",
    "    \"\"\"\n",
    "\n",
    "    # gold complenetess\n",
    "    df = check_completeness_qual(\n",
    "        df=df, columns_to_check=gold_completeness_cols, qual_level=\"gold\"\n",
    "    )\n",
    "    # silver complenetess\n",
    "    df = check_completeness_qual(\n",
    "        df=df, columns_to_check=silver_completeness_cols, qual_level=\"silver\"\n",
    "    )\n",
    "\n",
    "    # gold validity\n",
    "    df = check_value_ranges(\n",
    "        df=df,\n",
    "        max_allowable_epoch=max_allowable_epoch,\n",
    "        provider_ids=allowable_provider_ids,\n",
    "        qual_level=\"gold\",\n",
    "    )\n",
    "\n",
    "    # silver validity\n",
    "    df = check_value_ranges(\n",
    "        df=df,\n",
    "        max_allowable_epoch=max_allowable_epoch,\n",
    "        provider_ids=allowable_provider_ids,\n",
    "        qual_level=\"silver\",\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b2ee71b-5f7d-4785-a1b8-4c5ecda76acb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Define Data Quality Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7be89416-bdfb-4bc5-93ac-e083221d80ab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gold_completeness_cols = [\n",
    "    \"instrument_id\",\n",
    "    \"time\",\n",
    "    \"height_native\",\n",
    "    \"datum_native\",\n",
    "    \"provider_id\",\n",
    "    \"last_update\",\n",
    "]\n",
    "\n",
    "silver_completeness_cols = [\n",
    "    \"instrument_id\",\n",
    "    \"time\",\n",
    "    \"height_native\",\n",
    "    \"provider_id\",\n",
    "]\n",
    "\n",
    "gold_quality_cols = [\n",
    "    \"incomplete_gold\",\n",
    "    \"out_of_range_gold\",\n",
    "]\n",
    "\n",
    "silver_quality_cols = [\n",
    "    \"incomplete_silver\",\n",
    "    \"out_of_range_silver\",\n",
    "]\n",
    "\n",
    "all_qc_cols = gold_quality_cols.copy()\n",
    "all_qc_cols.extend(silver_quality_cols)\n",
    "all_qc_cols.extend([\"site_type\", \"time_delta\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24162e35-9a2c-4d1a-abd9-a10b9b7219e5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Apply Data Quality Checks in Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0b6ddf8-6e61-48a6-8a35-e7c67f676dc5",
     "showTitle": true,
     "title": "Run Quality Checks Function"
    }
   },
   "outputs": [],
   "source": [
    "def run_quality_checks(batch_df):\n",
    "    \"\"\"Applies the data quality checks to each micro batch in the spark stream.  \n",
    "\n",
    "    Args:\n",
    "        batch_df (sparkDataFrame):  micro batch in the spark stream\n",
    "    Returns:\n",
    "        sparkDataFrame: micro bath in spark stream with assigned data quality columns\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate an ingress (stream entry) time to measure processing latency\n",
    "    ingress_value = int(round(datetime.datetime.now().timestamp() * 1000))\n",
    "    batch_df = batch_df.withColumn(\n",
    "        \"ingress\", (F.current_timestamp().cast(\"long\") * 1000).cast(\"int\")\n",
    "    )\n",
    "\n",
    "    # Deduplicate measurements\n",
    "    batch_df = batch_df.dropDuplicates([\"instrument_id\", \"epoch\"])\n",
    "    batch_df = batch_df.withColumn(\n",
    "        \"time\", F.to_timestamp(F.from_unixtime(F.col(\"epoch\") / 1000))\n",
    "    )\n",
    "\n",
    "    # Perform Quality Checks\n",
    "    result_df = perform_quality_checks(\n",
    "        df=batch_df,\n",
    "        max_allowable_epoch=ingress_value,\n",
    "        gold_completeness_cols=gold_completeness_cols,\n",
    "        silver_completeness_cols=silver_completeness_cols,\n",
    "        gold_quality_cols=gold_quality_cols,\n",
    "        silver_quality_cols=silver_quality_cols,\n",
    "    )\n",
    "\n",
    "    # Create columns to track when a value was last updated\n",
    "    ## Epoch\n",
    "    result_df = result_df.withColumn(\n",
    "        \"last_update_epoch\", (F.current_timestamp().cast(\"long\") * 1000).cast(\"int\")\n",
    "    )\n",
    "    ## Timestamp\n",
    "    result_df = result_df.withColumn(\n",
    "        \"last_update\", F.to_timestamp(F.col(\"last_update_epoch\") / 1000)\n",
    "    )\n",
    "\n",
    "    # Creating a new column 'egress' to measure processing latency\n",
    "    result_df = result_df.withColumn(\n",
    "        \"egress\", (F.current_timestamp().cast(\"long\") * 1000).cast(\"int\")\n",
    "    )\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edf6dc45-8817-433a-a9bf-774f7c170782",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Apply Quality Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c858d326-5840-4766-891e-3fb1074eb5b2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Apply data quality checks function to streamed data set with transform\n",
    "etl_spark_quality_checked = simulated_etl_stream.transform(run_quality_checks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "226b2f3d-1f77-4ac8-b91a-bb779767b82d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Streaming Sink\n",
    "In reality, these values would be written out to an established sync such as a Delta Table or Confluent Kafka Stream. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "733b0abf-f105-4714-9f21-bb94b8b574ef",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### SQL Query"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41d91d75-a53c-4446-ae16-a2859bf38180",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Keep in mind, spark streaming doesn't allow for order by time (and it wasn't necessary for these specific implemented data quality checks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_query = (\n",
    "    etl_spark_quality_checked\n",
    "    .writeStream\n",
    "    .format(\"console\")  # Example sink (you can replace \"console\" with other sinks like \"memory\", \"parquet\", etc.)\n",
    "    .start()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7efea08a-890b-437b-afbc-a98f45606b5e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3321316446392305,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Solution Accelerator Part 1 - Quality Checks - Less Info",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
